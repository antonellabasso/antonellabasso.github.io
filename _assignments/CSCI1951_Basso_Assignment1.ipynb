
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment 1: Testing Bias\n",
        "\n",
        "Antonella Basso"
      ],
      "metadata": {
        "id": "Pn2rD0Pusrdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Outline\n",
        "\n",
        "Welcome to your first assignment! In this assignment, you will be learning about\n",
        "\n",
        "1. how to assess real-world deployments of algorithms for bias,\n",
        "2. how simple interventions when training a model might affect the fairness as measured using different approaches\n",
        "3. how to evaluate the efficacy of proposed fairness measures. \n",
        "\n",
        "We will be using Google Colab Notebook for the first assignment. We will provide a few tips on how to use Colab and make sure you read them carefully! \n",
        "\n",
        "☝ **Quick Colab Tips:**\n",
        "\n",
        "*   Make sure you **create a copy** of the Colab before you start coding!!! (File->Save a copy in Drive). If you don't do this, you will lose everything when you close the page and we DON'T want that to happen to you!\n",
        "*   Make sure you hit every play button that you need in previous cells, so that every function / variables you need is defined.\n",
        "*   If you don't want to click everything individually, you can click Runtime and you will find \"Run Before\", \"Run After\", or \"Run All\".\n",
        "*   When you reload the page, the runtime restarts and all variables in the environment are cleared, so you will need to re-run cells.\n",
        "*   If you make changes to a definition in an earlier cell, remember to run the cell to actually update the definition. Then remember to re-run the cells after, or else they will still be using the previous value. \n",
        "*   For more tips on getting started, please take a look at this [video](https://www.youtube.com/watch?v=inN8seMm7UI&ab_channel=TensorFlow)."
      ],
      "metadata": {
        "id": "O6pW9OzLM5Hx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part 1: Analyzing a real-world scenario for sources of bias"
      ],
      "metadata": {
        "id": "k0o1CCKTMkI_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We have discussed the different forms of bias that arise when designing a human-facing automated decision system. For reference, look at Figure 2 from the [NIST Special Publication](https://nvlpubs.nist.gov/nistpubs/SpecialPublications/NIST.SP.1270.pdf) on identifying and managing bias in AI. \n",
        "\n",
        "In this question you will apply your understanding of statistical/computational biases to a real-world scenario. The goal is to identify potential sources of bias in the example and list them with justification. Make sure to distinguish whether the identified sources are likely to appear in the data collection/representation stage, the training/model building phase, or the inference/action stage of the data processing pipeline. \n",
        "\n",
        "## The Scenario\n",
        "\n",
        "Health care systems use automated tools to determine whether a patient should be inducted into an intensive \"care management system\" to cure what ails them. The idea is to determine which patients can benefit the most from being admitted to the system because it is expensive, and not everyone can be enrolled. \n",
        "\n",
        "It is hard to know who will benefit the most, so the systems instead try to predict a proxy: who will incur the most health care costs. The idea is that if your health care costs are predicted to be large, you probably need intensive treatments to be cured, and so you're likely to benefit. \n",
        "\n",
        "The algorithm that makes this prediction uses the following training data set: \n",
        "input features for an individual are a list of insurance claim data from the previous year. Each such claim consists of\n",
        "\n",
        "\n",
        "1. Demographic information (age, sex, but not race)\n",
        "2. Type of insurance (private, medicare, medicaid, hmo, etc, )\n",
        "3. Disease diagnosis (usually expressed in a standard code)\n",
        "4. Procedures performed (X-rays, MRIs, surgeries, etc, each expressed with a specific code)\n",
        "5. Medications\n",
        "6. Costs\n",
        "\n",
        "The goal is to predict the cost of care this year. Formally, this is a regression problem with a mix of numerical and categorical variables, and a numeric output. \n",
        "\n",
        "**Question:** For each category of bias in the data processing pipeline, discuss what kind of bias might appear in this scenario, and how. "
      ],
      "metadata": {
        "id": "GLRHnHMKOWOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Type in your reponse here ###"
      ],
      "metadata": {
        "id": "hGoE8xMyXmRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Response\n",
        "\n",
        "This is my favorite example of racial discrimination in automated decision making. I commonly use it to explain (to others) how an algorithm may still favor a particular social group(s) in prediction, despite being \"blind\" to group membership in the data. Namely, this case exemplifies the ways in which *algorithmic neutrality* not only fails to prevent biased decisions, but leads individuals to believe that their outcomes are fair and accept injustice willingly.\n",
        "\n",
        "It’s no surprise, given our nation’s historical legacies of oppression and racism towards Black and Brown individuals, that communities of color continue to experience systemic injustices on disproportionate levels. Among these are both the degree and quality of healthcare provision, as reflected in insurance claims data, which proves that healthcare expenditures in the U.S. are disparately low for marginalized groups. Thus, any model that utilizes this data to predict future healthcare costs is bound to replicate the systemic biases embedded within it to generate an adverse *feedback loop* of discriminatory outcomes&mdash;that is, unless used in tandem with a processing strategy explicitly designed to remove them. In this way, healthcare expenditure becomes a *proxy* for race, making its use as a basis for allocating those in more urgent need of care an implicit method for discriminating against vulnerable populations and keeping marginalized individuals on the margins. \n",
        "\n",
        "**Selection/Sampling Bias:**\n",
        "\n",
        "- *ecological fallacy*: \"Occurs when an inference is made about an individual based on their membership within a group.\" The implicit assumption that disadvantaged racial groups receive the same form of care or benefits than their privileged counterparts could be interpreted as an ecological fallacy. \n",
        "\n",
        "- *detection bias*: \"Systematic differences between groups in how outcomes are determined and may cause an over- or underestimation of the size of the effect.\" Detection bias in this case stems from the fact that marginalized and non-marginalized racial groups benefit from healthcare on disparate levels which in turn leads the system to underestimate the care needs of individuals of color.\n",
        "\n",
        "- *measurement bias*: \"Arises when features and labels are proxies for desired quantities, potentially leaving out important factors or introducing group or input-dependent noise that leads to differential performance.\" Similar to measurement bias, the computational  bias reflected in this scenario can be attributed to the fact that the desired quantity is itself a proxy for a factor we do not wish to have any influence over decisions. \n",
        "\n",
        "**Processing/Validation Bias:**\n",
        "\n",
        "- *model selection bias*: \"...Model selection bias also occurs when an explanatory variable has a weak relationship with the response variable.\" Evidently, there is a weak relationship between the predictor and outcome in this case, given that insurance claims data (itself contaminated with systemic biases), rather than being able to distinguish those with more critical health conditions who may largely benefit from care management, reflects which (groups of) individuals have been previously prioritized by the system and are hence responsible for the majority of health care expenses regardless of actual health status.\n",
        "\n",
        "- *survivorship bias*: \"Tendency for people to focus on the items, observations, or people that 'survive' or make it past a selection process, while overlooking those that did not.\" Decision-makers using the model discussed in this example are likely to display survivorship bias (at least to some extent), as their presumed goal is to select individuals with high projected care costs for admission into the care management system, while overlooking those with low cost predictions.\n",
        "\n",
        "**Use & Interpretation Bias:**\n",
        "\n",
        "- *feedback loop bias*: \"Effects that may occur when an algorithm learns from user behavior and feeds that behavior back into the model.\" If the overall intent is to use this model to predict future healthcare care costs beyond the following year, feedback loop bias will be an inevitable consequence due to the perpetual use of biased data for prediction&mdash;in accordance with the renowned saying “bias in, bias out”.  \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ppmukE9K8_RC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 2: Experimenting with the ways in which design choices affect fairness"
      ],
      "metadata": {
        "id": "KLL-DgqPMvJ7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Part 2, you will be working and playing around with codes for a bit. We will ask you to \n",
        "1. Build a basic pipeline to train the model and evaluate the model with three fairness measurements.\n",
        "2. Resample the datapoint from the dataset and observe the changes in evaluation.\n",
        "3. Use a different cost function for trianing and observe the changes in evaluation. "
      ],
      "metadata": {
        "id": "szHOYSfynU92"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation"
      ],
      "metadata": {
        "id": "eSXTy2-oOdTq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Cython\n",
        "!pip install sklearn\n",
        "!pip install folktables"
      ],
      "metadata": {
        "id": "NKV3YWA1bg7H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "687bc43c-d5e2-45c7-80b5-f8837eff4ae7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: Cython in /usr/local/lib/python3.8/dist-packages (0.29.33)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.8/dist-packages (0.0.post1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: folktables in /usr/local/lib/python3.8/dist-packages (0.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from folktables) (2.25.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from folktables) (1.21.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from folktables) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.8/dist-packages (from folktables) (1.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->folktables) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->folktables) (2022.7.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->folktables) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->folktables) (2022.12.7)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->folktables) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->folktables) (1.24.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->folktables) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->folktables) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn->folktables) (1.7.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->folktables) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from folktables import ACSDataSource, ACSPublicCoverage"
      ],
      "metadata": {
        "id": "bALR4XI-bbOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2a"
      ],
      "metadata": {
        "id": "vaHzvE_mO_ox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset and Preprocessing"
      ],
      "metadata": {
        "id": "PltCoRUkPBB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this part of the assignment, you will be working with a dataset from [Folktables](https://github.com/zykls/folktables), a Python package that provides access to datasets derived from the US Census. The data provided by this library is sourced from the [American Community Survey](https://www.census.gov/programs-surveys/acs), a demographics survey program that gathers information about individuals' educational attainment, income, employment, demographic information, etc. This is particularly useful for measuring fairness in machine learning models as you will see later on this the next section.\n",
        "\n",
        "First, you will need download and process a dataset from California 2018. We already provide you with the code which handles preprocessing and train-test split. In the context of this assignment, you will be working with the `ACSPublicCoverage` prediction task as defined by Folktables.\n",
        "\n",
        "*   This is a binary classification task that asks you to predict whether a person has a public coverage or not based on the given a set of features such as age, sex, race, and different types of disabilities.\n",
        "*   One of the features used in prediction is race which is a sensitive attribute and ideally should not have correlation with the prediction. Your goal is utilize different techniques to make your model more fair in its prediction.\n",
        "\n",
        "Let us begin by observing the dataset. You might find the [ACS PUMS documentation](https://www.census.gov/programs-surveys/acs/microdata/documentation.html) helpful when interpreting the feature codings."
      ],
      "metadata": {
        "id": "zUGwfu2hQJVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from folktables import ACSDataSource, ACSPublicCoverage\n",
        "\n",
        "# import data source form ACS\n",
        "data_source = ACSDataSource(survey_year='2018', horizon='1-Year', survey='person')\n",
        "acs_data = data_source.get_data(states=[\"CA\"], download=True)\n",
        "prediction_task = ACSPublicCoverage\n",
        "\n",
        "# gather columns defined in the ACSPublicCoverage prediction task\n",
        "features, label, group = prediction_task.df_to_numpy(acs_data)\n",
        "\n",
        "# aggregate features and target variable into the same dataframe\n",
        "acs_public_coverage_data = acs_data[prediction_task.features\n",
        "                               + [prediction_task.target]]\n",
        "\n",
        "###### Data summary ######\n",
        "print(acs_public_coverage_data.head())\n",
        "print(\"features used for predictions: \"   + str(prediction_task.features))\n",
        "print(\"group membership variable: \"       + str(prediction_task.group))\n",
        "print(\"the target variable of interest: \" + str(prediction_task.target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uuSaGyfWudV",
        "outputId": "cb9fb38c-113c-42ed-e461-1d96fc152f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   AGEP  SCHL  MAR  SEX  DIS  ESP  CIT  MIG  MIL  ANC  NATIVITY  DEAR  DEYE  \\\n",
            "0    30  14.0    1    1    2  NaN    1  3.0  4.0    1         1     2     2   \n",
            "1    18  14.0    5    2    2  NaN    1  1.0  4.0    1         1     2     2   \n",
            "2    69  17.0    1    1    1  NaN    1  1.0  2.0    2         1     2     2   \n",
            "3    25   1.0    5    1    1  NaN    1  1.0  4.0    1         1     1     2   \n",
            "4    31  18.0    5    2    2  NaN    1  1.0  4.0    1         1     2     2   \n",
            "\n",
            "   DREM    PINCP  ESR  ST  FER  RAC1P  PUBCOV  \n",
            "0   2.0  48500.0  6.0   6  NaN      8       1  \n",
            "1   2.0      0.0  6.0   6  2.0      1       2  \n",
            "2   2.0  13100.0  6.0   6  NaN      9       1  \n",
            "3   1.0      0.0  6.0   6  NaN      1       1  \n",
            "4   2.0      0.0  6.0   6  2.0      1       1  \n",
            "features used for predictions: ['AGEP', 'SCHL', 'MAR', 'SEX', 'DIS', 'ESP', 'CIT', 'MIG', 'MIL', 'ANC', 'NATIVITY', 'DEAR', 'DEYE', 'DREM', 'PINCP', 'ESR', 'ST', 'FER', 'RAC1P']\n",
            "group membership variable: RAC1P\n",
            "the target variable of interest: PUBCOV\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see, this summary doesn't really give us any information more than what attributes are used in the prediction task or what the prediction target is. One simple way to better our understanding is to visualize the distribution of some features of interest such as group membership attributes or the target label. We will explore both possibilities here."
      ],
      "metadata": {
        "id": "g0eZ4oki-QYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "###### Data visualization ######\n",
        "race_coding = [\n",
        "    'White alone',                # White alone\n",
        "    'Black or African American',  # Black or African American alone\n",
        "    'American Indian alone',      # American Indian alone\n",
        "    'Alaska Native alone',        # Alaska Native alone\n",
        "    'American Indian and ...',    # American Indian and Alaska Native tribes specified; \n",
        "                                  # or American Indian or Alaska Native,\n",
        "                                  # not specified and no other races\n",
        "    'Asian alone',                # Asian alone\n",
        "    'Native Hawaiian',            # Native Hawaiian and Other Pacific Islander alone\n",
        "    'Some Other Race alone',      # Some Other Race alone\n",
        "    'Two or More Races']          # Two or More Races\n",
        "\n",
        "# bar graph by group membership\n",
        "(acs_public_coverage_data\n",
        " .groupby([prediction_task.group])\n",
        " .size()\n",
        " .set_axis(race_coding)\n",
        " .plot(kind='bar', rot=-90))"
      ],
      "metadata": {
        "id": "ktSh-oySpUCa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "5f1ea1c8-f70f-4d22-dbfd-92e57d860fc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f377d5ee100>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAFwCAYAAABNQIdsAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dZ7hkVZn28f9NI6AYQAkiiKBiFhEQGRXFRNARA4gZZFBQEXV0ZgRHB+OYFXEYDK8kE5hBRR0GdAQRhyaDwpAVA6AgQSU03O+Htaq7+lD79Onuc2rtou/fddXVtVeF/fTq6npqryjbREREjLJS6wAiIqK/kiQiIqJTkkRERHRKkoiIiE5JEhER0SlJIiIiOq3cOoDZttZaa3mjjTZqHUZExEQ5/fTT/2h77anld7kksdFGGzF//vzWYURETBRJV4wqT3NTRER0SpKIiIhOSRIREdEpSSIiIjolSURERKckiYiI6JQkERERnZIkIiKi011uMt1MbLTf92ftvS7/0HNn7b0iIvomVxIREdEpSSIiIjolSURERKckiYiI6JQkERERnZIkIiKiU5JERER0SpKIiIhOSRIREdEpSSIiIjolSURERKckiYiI6JQkERERnZIkIiKiU5JERER0SpKIiIhOSRIREdEpSSIiIjolSURERKckiYiI6JQkERERnZIkIiKiU5JERER0SpKIiIhOSRIREdFpiUlC0gMl/VjSLyWdL+nNtfy+ko6XdFH9c81aLkkHSbpY0jmSNh96r93r8y+StPtQ+RaSzq2vOUiSpjtHRESMx0yuJBYAb7P9KGBrYB9JjwL2A06wvQlwQj0G2BHYpN72Ag6B8oUPHAA8EdgKOGDoS/8Q4LVDr9uhlnedIyIixmCJScL2722fUe/fCPwKWB94PnBEfdoRwAvq/ecDR7o4FVhD0nrA9sDxtq+1fR1wPLBDfezetk+1beDIKe816hwRETEGS9UnIWkj4PHAL4B1bf++PvQHYN16f33gN0Mvu7KWTVd+5YhypjnH1Lj2kjRf0vxrrrlmaf5KERExjRknCUn3BL4JvMX2DcOP1SsAz3Jsi5nuHLY/Z3tL21uuvfbacxlGRMQKZUZJQtLdKAniy7a/VYuvqk1F1D+vruW/BR449PINatl05RuMKJ/uHBERMQYzGd0k4AvAr2x/YuihY4HBCKXdgWOGynero5y2Bq6vTUY/AraTtGbtsN4O+FF97AZJW9dz7TblvUadIyIixmDlGTznycCrgHMlnVXL3gF8CPiapD2BK4Bd62PHAc8BLgb+CuwBYPtaSe8DTqvPe6/ta+v9NwCHA3cHflBvTHOOiIgYgyUmCdsnA+p4+Jkjnm9gn473OhQ4dET5fOAxI8r/NOocERExHplxHRERnZIkIiKiU5JERER0SpKIiIhOSRIREdEpSSIiIjolSURERKckiYiI6JQkERERnZIkIiKiU5JERER0SpKIiIhOSRIREdEpSSIiIjolSURERKckiYiI6JQkERERnZIkIiKiU5JERER0SpKIiIhOSRIREdEpSSIiIjolSURERKckiYiI6JQkERERnZIkIiKiU5JERER0SpKIiIhOSRIREdEpSSIiIjolSURERKckiYiI6JQkERERnZIkIiKiU5JERER0WmKSkHSopKslnTdU9m5Jv5V0Vr09Z+ix/SVdLOlCSdsPle9Qyy6WtN9Q+caSflHLj5a0Si1ftR5fXB/faLb+0hERMTMzuZI4HNhhRPknbW9Wb8cBSHoU8FLg0fU1/ylpnqR5wMHAjsCjgJfV5wJ8uL7XQ4HrgD1r+Z7AdbX8k/V5ERExRktMErZ/Clw7w/d7PnCU7VtsXwZcDGxVbxfbvtT2rcBRwPMlCXgG8I36+iOAFwy91xH1/jeAZ9bnR0TEmCxPn8QbJZ1Tm6PWrGXrA78Zes6Vtayr/H7An20vmFK+2HvVx6+vz4+IiDFZ1iRxCPAQYDPg98DHZy2iZSBpL0nzJc2/5pprWoYSEXGXskxJwvZVtm+3fQfweUpzEsBvgQcOPXWDWtZV/idgDUkrTylf7L3q4/epzx8Vz+dsb2l7y7XXXntZ/koRETHCMiUJSesNHb4QGIx8OhZ4aR2ZtDGwCfC/wGnAJnUk0yqUzu1jbRv4MbBLff3uwDFD77V7vb8LcGJ9fkREjMnKS3qCpK8C2wJrSboSOADYVtJmgIHLgb0BbJ8v6WvAL4EFwD62b6/v80bgR8A84FDb59dTvB04StL7gTOBL9TyLwBflHQxpeP8pcv9t42IiKWyxCRh+2Ujir8womzw/A8AHxhRfhxw3IjyS1nUXDVcfjPw4iXFFxERcyczriMiolOSREREdEqSiIiITkkSERHRKUkiIiI6JUlERESnJImIiOiUJBEREZ2SJCIiolOSREREdEqSiIiITkkSERHRKUkiIiI6JUlERESnJImIiOiUJBEREZ2SJCIiolOSREREdEqSiIiITkkSERHRKUkiIiI6JUlERESnJImIiOiUJBEREZ2SJCIiolOSREREdEqSiIiITkkSERHRKUkiIiI6JUlERESnJImIiOiUJBEREZ2SJCIiolOSREREdEqSiIiITkkSERHRaYlJQtKhkq6WdN5Q2X0lHS/povrnmrVckg6SdLGkcyRtPvSa3evzL5K0+1D5FpLOra85SJKmO0dERIzPTK4kDgd2mFK2H3CC7U2AE+oxwI7AJvW2F3AIlC984ADgicBWwAFDX/qHAK8det0OSzhHRESMyRKThO2fAtdOKX4+cES9fwTwgqHyI12cCqwhaT1ge+B429favg44HtihPnZv26faNnDklPcadY6IiBiTZe2TWNf27+v9PwDr1vvrA78Zet6VtWy68itHlE93jjuRtJek+ZLmX3PNNcvw14mIiFGWu+O6XgF4FmJZ5nPY/pztLW1vufbaa89lKBERK5RlTRJX1aYi6p9X1/LfAg8cet4GtWy68g1GlE93joiIGJNlTRLHAoMRSrsDxwyV71ZHOW0NXF+bjH4EbCdpzdphvR3wo/rYDZK2rqOadpvyXqPOERERY7Lykp4g6avAtsBakq6kjFL6EPA1SXsCVwC71qcfBzwHuBj4K7AHgO1rJb0POK0+7722B53hb6CMoLo78IN6Y5pzRETEmCwxSdh+WcdDzxzxXAP7dLzPocChI8rnA48ZUf6nUeeIiIjxyYzriIjolCQRERGdkiQiIqJTkkRERHRKkoiIiE5JEhER0SlJIiIiOiVJREREpySJiIjolCQRERGdkiQiIqJTkkRERHRKkoiIiE5JEhER0SlJIiIiOiVJREREpySJiIjolCQRERGdkiQiIqJTkkRERHRKkoiIiE5JEhER0SlJIiIiOiVJREREpySJiIjolCQRERGdkiQiIqJTkkRERHRKkoiIiE5JEhER0Wnl1gFExNzYaL/vz9p7Xf6h587ae8VkyZVERER0SpKIiIhOSRIREdEpSSIiIjotV5KQdLmkcyWdJWl+LbuvpOMlXVT/XLOWS9JBki6WdI6kzYfeZ/f6/Isk7T5UvkV9/4vra7U88UZExNKZjSuJp9vezPaW9Xg/4ATbmwAn1GOAHYFN6m0v4BAoSQU4AHgisBVwwCCx1Oe8duh1O8xCvBERMUNz0dz0fOCIev8I4AVD5Ue6OBVYQ9J6wPbA8bavtX0dcDywQ33s3rZPtW3gyKH3ioiIMVjeJGHgvySdLmmvWrau7d/X+38A1q331wd+M/TaK2vZdOVXjiiPiIgxWd7JdE+x/VtJ6wDHS7pg+EHbluTlPMcS1QS1F8CGG24416eLiFhhLNeVhO3f1j+vBr5N6VO4qjYVUf+8uj79t8ADh16+QS2brnyDEeWj4vic7S1tb7n22msvz18pIiKGLHOSkLS6pHsN7gPbAecBxwKDEUq7A8fU+8cCu9VRTlsD19dmqR8B20las3ZYbwf8qD52g6St66im3YbeKyIixmB5mpvWBb5dR6WuDHzF9g8lnQZ8TdKewBXArvX5xwHPAS4G/grsAWD7WknvA06rz3uv7Wvr/TcAhwN3B35QbxERMSbLnCRsXwo8bkT5n4Bnjig3sE/Hex0KHDqifD7wmGWNMSIilk9WgY2IFd5srZh7V1wtN8tyREREpySJiIjolCQRERGdkiQiIqJTkkRERHRKkoiIiE5JEhER0SlJIiIiOiVJREREpySJiIjolCQRERGdkiQiIqJTkkRERHRKkoiIiE5JEhER0SlJIiIiOiVJREREpySJiIjolCQRERGdkiQiIqJTkkRERHRauXUAERFxZxvt9/1ZeZ/LP/Tc5Xp9kkRPzNYHApb/QxERMZDmpoiI6JQkERERnZIkIiKiU5JERER0SpKIiIhOSRIREdEpSSIiIjolSURERKckiYiI6JQkERERnZIkIiKiU5JERER06n2SkLSDpAslXSxpv9bxRESsSHq9CqykecDBwLOBK4HTJB1r+5dtI1tx9GW54ohoo9dJAtgKuNj2pQCSjgKeDyRJREygLIk/eWS7dQydJO0C7GD7NfX4VcATbb9xyvP2Avaqhw8HLpylENYC/jhL7zVbEtPMJKaZ62NciWlmZjOmB9lee2ph368kZsT254DPzfb7Sppve8vZft/lkZhmJjHNXB/jSkwzM46Y+t5x/VvggUPHG9SyiIgYg74nidOATSRtLGkV4KXAsY1jiohYYfS6ucn2AklvBH4EzAMOtX3+GEOY9SasWZCYZiYxzVwf40pMMzPnMfW64zoiItrqe3NTREQ0lCQRERGdkiQiIqJTksQMSVpP0s6SPtE6lr6QdIKkvSSt2TqWgcQ0c32Nq28kbS7pYUPHq0t6oaStW8bVRdJ9Z/P9kiRGkLSSpMdJer2kL0q6BPgF8GLg8kYx3SbpRkk31NuCoePbW8QEfBh4PHClpO9Kermk1RvFkpiWXu/iqp/n4c/54Phvku5oFNangTtqfAJOBl4NfFzSvzaKaTonzOq72c5tyg34M3AJ8CngJcAGPYjpjK7jqY81iO0y4JnA54HfAEcBL0hM/Y+pz3HV2O4JvL3+f/xooxjOG7r/VOCCen/l4cf6cpvt74Nez5No6FPA3wFPBu4D3EfSKcD5rv8KDWjK8d2H7re+IrTtE4ATJD0U+ALwLdrGlZhmrndx1SawNwO7A18GnmD72kbhLBi6/wzqL3WXeVxNruIlHdDxkIH1ZvNcSRIj2D4AFl5aPoaSMP4JeIykP9reoUVckh5h+4LaFnp/SS8GrmfxD3EL8yTtS7nqWgv4KvDatiElpqXQm7gkrQO8DdiVkqw2tX1ji1iGXCzpfcBZlIVEXwoL2/5bNfUO18ngB+RKlHhmNaYkiemtQVkvan3g/sAtwK8bxbI/8NPaLvtHyi+adwH3Bd443QvnSp0NvzPl18uGwL62z2wRy1BM+wIv6llMvasn6G1clwJ/oiSIvwF7ld9qhe2PN4hpL+DdwG7AfrZ/WstXAfZuEA+2PyHpQcBTKE1gTwJusb2lpFfO5rky43oESYcBj6X0Tfwc+Bnwc9vXN45LwP1s92K5YkkHA1+1fXLrWAYS08zVuI6yfVLrWAYkvYs7N60uZPu9YwxnIUmrUrYhALjQ9i0t4hiK54p690vAScDJtm+qj51he/NZO1eSxJ1J+iXlKuLn9XYKMN/2rQ1jetB0j9u+YrrH54Kkp3XE8j/jjmUg9TRzknYDfmL715K2AZ4AfMX2H1rG1TeSng4cBlxBuep6MLBH7cdpFdOewNOATSitGz+lJIqzJa1se9aaoJMkOtT2xifV25MpVxYXAKfY/qcG8Zwz3cO2Hzu2YAYnlYZX5F2V8iVzju1txx3LQOpp5iSdCzwOWIfyJXMYZZOvkUltTDHtBBwA3ADsSxlttY3t7zWM6QxgFy/aIfMhwNdn89f68pD0fOAdlM79WR9skCQxQ5JWBjYHnmT7wNbx9FHtdPyc7Re0jqXP+lJPg2aJ+qt0fdvvne2mimWI6RJgF+ABwJtsby/pVNvNJq5JOtv245ZUNuaY9qf0R9wXOBv4H+Ak21fO9rnScT1CV/NA1aRjrw5NfANlNNMngduAdVo0n0zjz5TRYM2knpbKjZL2AV4DvLr2ebX+Tri2dp6fKemDtexuLQMCTqv9lF+sx7tT9rpp6SWUJvHjKH2mP5uLBAG5khhpRPPAVpThbzdS6ux5DWI6GzicMgb6/pT/2P9t+6njjmUophNZfPjdQ4Av2t6/YUyppxmStCHwFsrkqy/V2dab2f5Zw5g+DKwNHAF8BvgY8BLb2zWM6W6UUUzb1qKfAofYvq1VTACS7kO5mtim3ta1/dBZP0+SxJJJWg84yPaLG8Zwpu3H1/vn2N5UjffclTTcLLEqsB1wke2vNAop9TThakIduBk4H/iI7WsahTQxJK1m++bZft/Wl5aT4g+0bx74oaQ9gCOB22uzSlO2z5hS9HNJvwBafvmlnmZI0qUsPtzUlB+OG0v6nu2/H3dMtp8xtWxJI9bm2oh6AsD2xg3CARZeBR5EGVgjyijMfSkjsGZVksQIkg5i0YdiHrAZML9dRADsA6wOfBa4lTIrtskkuoEpfTcrUUaArdYonIE3UNb7ST0t2XRXVy8fWxRDJG0CPA+411Dx6yR9hjJct8Ww4eF6WpUS30YN4hh2WL3tXI9fBhxKWYNrVqW5aYQ6fnxgAXC57VNaxdNXU/puFlBWyP207cvaRNRPfa0nSasAOwDXt56zMVD7lL5NGQI78I/AgZTh5z9vEtgUw82ajc5/lu3NllQ2K+dKkpgckrYHnl0PT7D9g5bx9FEmiM2cpOMoo7/WBE6kfBEfZvuFDWO60xDcHgzL3X3ocHAl+BTbWzUKCUnHUxY+/FItehXwctvP7n7Vsmm9+mQvSTpR0o+n3upjn2sU079Q1mr6Vb39q6S3t4hlKKb7SfqSpKslXSXpy5LWahkT8M+U/RHuT1n/Z1Xg6JYB9bSeAB5k+/mUHx4vsP1nylplLe07w7Jx2mLotjVl3bQmazYN2YPS7PU74PfATrVs1qVPYrTpZlS32plud2BL238DkPQlyljtDzeKB+BgSl/NHpRNmQ6mDFvcpWFMt9m+Q9JzgS/Z/qDKarkt9bGeAC7UopWFkbQa7ftKninpWSPKfyZpb9ufHXdAtt80fCzpHpSl1JusBg1Q50TsvMQnzoIkiRFGjEahTuw5w/YFDUKCssLj3wYHtm9Rux3pBh5pe7BssmyfIumTjWPq4wSxPtYTlMlYZ0o6FXgQ5UfHp9qGxE3TPPaXsUUxvXtQ5rqsEFr/5+mlmhD2oiwFDGVo4D1Ullb+d9sf7Hzx3DlO0pq2r6sxrgG07pOYN3wg6YGtAhnyKsoEsY/Xxc5WB17fOKY+1hOU5a8HbqbM3biuUSxAWQJ7apmkh9fHvnTnV8y9oSGwpjTRr0ZZX2qFkI7rEVRWgX2s7duHypp2nvWRpP8EPlu/jH9N+RW4Z19GoPRF6mnpSXowZemJF1OaEJ/YMJb7Dh0usH1D55PvgpIkRpD0RduvWlLZmGMaXtrhTmw/fYzh3Imke9j+a8sYahw3UOpp0Mx0K4t+Bcr2vaZ5+ZzrSz3BYnVlyvpIqwJ/aVlHkt5GSQ7zKAMOju7DuluSng1sT6mr/7J9fON41qRczWxD+Tc8GThgLq4EkyQ6SHokZWKKKcNNW/VFDOIZXMXsSVm6fG/K8EVgdD/KGGIaeclt+z3jjmVY7Yc4lDIa5Vm2r24cTy/raSpJz6GscvzOhjHcThna+T7bF7WKY5jKbocvp3ym9geOpzTNfaxhTN8GTmfxIbCbz8Xw5QyBHUHSrsB3KIvE7Q98RNIrWsZUk8BTKZuMHE3ZJP5M22e0SBDVjUO3O4C/p3GHXp0g9g3K0MB9gGN7MNy0d/U0iu3jKLG1tDFwDvAVSadL+pfWy3JQ9vt+lu3PA3+2vTdlD+6WHmz7/bYvr7f3UTZDmnW5khhB0pnAdravUdlw5AmU2Z4t20XfDTwe2LWObNofeJjtORkbvSzqF/SJtp/SMIYf1Bg+Wo+fAbzf9pNaxTRVH+qpxjE8hHIe5cprm77UlcrmPi8BXmp704ZxnDM4f/1u2JzyA23WZzcvRUynAO+w/ZN6/HTgA3Pxb5fRTaOtNLTqpGzfrrJccEubAC8adKbX8f9N9vvtYvtWSVdImjfc6T9mx9j+zFBMJ0p6X6NYRupJPQE8d+j+YLmQ57cJZZH6f+3hlKbej9j+98Yh3SjpAbZ/R1k/7VjK0iEtvRY4cugq+VpKk9Osy5XECJJOo1xJXCfpV5QlC1ay3XooZa9omr2bJW1h+/QGMT2E0sw02HToVso6+806P/tYT30laVNKc+E1lJWXz6PsUNesjiRtDNxUWxb2oPRHnNwqnmGS7glge7r5Jct3jiSJO5O0FfCHuv7PvwGXAl92KmsxWnzhuoXFtp8n6UDbb2kQUx83HepdPfWVpP8B3m771NrU+2zgm268H3jfjHMwRJJE3KWoh5sOxcxpaCXTwb+lpNNsP6F1bH0i6a1Dh6tT1m76le3dOl6yzNInMUEkrUppqwW40PYtjeNZHXgni1am/W/K0MWWyyf0btOhntZTX82TtLLtBcBKdaThH1sH1TdTZ6arbPt6YsfTl0uGwE6IOnrhQuDTlB2pLpI06xuMLKWDKROwXlJvq1Dia2kf4P8Bf6N09jffdIh+1hOStpb0TUmHSdpA0j0ltf7FfiDwsHr/d5QJbK9uFs0QSQ+R9Lx669UQZtu3AldImrfEJy+lNDd1UNlk/ObWv9YHavvsLrYvrccPAb7ecqkQSefafuyUsoXDBaPoaz1JuhDYD1ifsvz1LsDJfRkC2xf1u+ALlCHoZ9XizYAzKMur3KWX6ciVxAh1aOkFlMy8s6Q1JL2rcVjzBgkCwPYlTFk4roEFI8ruGHsU/dfXerrJ9rdt/wewie07KFc8sbj/AM62/RDbO9veGXgocC49uCKca0kSo72csoft5sA/u2zG0nom6mm1WeAZ9XYEZWnnlt6jshotsPAXV6+WmuiJvtbT9yW9u85odm2+/NuSXrQC+rs6o3khF+8F7vJXXWluGkHSScCOtm8aGiHTtHmgTjDaG9i2Fv0UOMT2bZ0vGoM6rv0G25e3jKPv+lhPKktgD9wM/BLYvy9rJvWFpItsb7K0j81xTNMuVTKb84KSJEaQ9AVgK8qkntcAPwb+avt1TQPrGUmHUdpm7wl8HDiKst/GG5oG1jOpp5nrGv8/0GJRRElHAhdTRqS5lq0E/Buwke1XN4jpHBat4AuLVoi+B7Cx7VlrJcoQ2NGuqDcobY7n2/5+w3iGNz5ZjO2NG4Qz8HfAI4F7AT+2/RlJTecjaPHlrxcWUz7rq87mf56l0Lt6gu6Z4AO2/2dcsQy5ccrxW2m3ZfDAGykd15dIGnRcP46yCutrWgQ03KohaWXKVqovpXzO3j+b50qSGKG2NfbN8JfK6pShlK1XN/0NsI7tqyStXH9d3b1lQLbvPXxcly3Yh7LT4LeaBNXDeqreNs1jAsaeJEaM/3/l1LJxq6OXXqyyEdKjavEvhweStCDpUZR/wy0oy5d/wnOwInSSxAiSDmX6DX7GvvKq7WuHDq8FPiZp/rjjmOJ64GyVlVfvD5xAaaJrTmVTljcDu1P2J3jClDocp17Wk+2dWscwCeov9U0pV4KDK50vq6zEfFnDdcG2AHakXGkdZfvKuThJ+iRGkPSi6R633eoX6WLqbNRv1KGLLc4/vATAzZRfV+e1iGVA0jqUX1e7UpoIPmV7ahPGuGPqXT3BwkT6bsruZjCHu5stq+FlVhrGcAJlJOjw52gbSn19xfZXmwQGg73ud6G0LKxM2Wvm67b/NGvnSJIYrW9LYMTMSLoJ+BMlQdxp2QvbHx97UD2lMe5uthQxDfreBl9MDwB+z6LtZ8feBzcqUanxnveSdp9SZEpd7Qo8xvYqs3WuNDeNUJfAOIzSeW3gwZL2sH1C28j6paed6R9mUUyrN4xjoZ7WE5TdzYYTwvvqKrotNe/QH+HwEWVHjDuIKbboKD+53mZNksRoHweeMXUJDMrkuiYkPRU4qWfLlQ//h14VeCGwTqNYAJg66akneldP1V8kbevFdzdrvejgTZSROtc3Gl01ynUjfrn/eVBme+wJw/abxnWuNDeNIOls249bUtmYYzoF2AD4GvBV93SjGkmn2+76lTOO8+8EHADcAOxLGVm0je3vtYpplNb1VGN4NGW13MV2N2vZXyLpOOA2YE3KqqYHAoc1bgI7aOhwVeCZwNnAbynfofs2iGlDykKfT6Jcpf4c2HcuOtGTJEaQ9P8o6yJ9sRbtDtxmu8mY6AFJ61J26rqQ8h/7aErCuKBRPMNfcoM9kl/XOJleQunIewBlR7PtJZ1qe+uGMfWunoZpDLubLUUs59t+dO0T/IXtzdSz/SRqfX3d9o4NYziB0iQ+6DR/GbCH7VlfGTrNTaO9nrIExmBG7E+BQ9qFU9Rx9jfafoqkDSiTZ74m6Q632ZT9o0P3F1D6cF7cII5h19o+EzhT0gdrWev9yftYT3ea3SyVbpMWs5qHXCjpEbYvkISk1YDVGsYzym3AgxvHcD/bXxo6/pKkf5qLEyVJjFDXQ/qPeusb1TXjH1lvawIntQjE9jNanHcJTqzzXI4A7iZpT8pop2Z6Wk+w+JDOVYHnUq5SW1qDkuBPBR5EWcTyUy0DUtl+djDwYCXg0ZSr+JaukfRqFh+Zds1cnCjNTSP0cTRKnaX7VOA7lP/cZwJfAY6xnZU7K0nDu3PdDJwPfMT2nPwHuiupk8aOt/30hjEM70V+M3BR63kbU2JaAFxh+7et4gGoLQmfYtEcl59R+iRmfUJdksQIku47dLhwNIrtd7eJCCT9DvgVJTF8sy5fHjMg6UENZ8VODEn3o/QDNN/ydaD2w21ju+kMdUlrAVtThsSfOpuT1fouSWKGWo9GkXR/23+YUnaI7de3iqmPJG0CPI+yhMLA64DPAD/p0bDK5qasJDoPWBd4j+1mG+nU9ZG2AZ5CGblzE2W3vOnWmZrrmLalzJX4GbAdZUn199s+vmFMI5cOmoslg0GtEdoAABEsSURBVNInMULHaJTWdXWKBj2LhYH16wf4ENsHjX7Z3OnpKqLfAL5NGQI7sIDyZXNrg3j6Wk+w+EZaC4CrbN/eKJaBi4ArgY8B/9iHEVfAR4Bn2r5EZRvhHSjrbzVLEsDwkO7VKQMh5qQJLFcSI0xp114AXA58zPb/tYnoTk1gUJLETygLfP237Ufd6UVzH9Ox0z1s+3ljC2Zw0hHLJfRgCYXe1dPCk0uPpIz7N3BCq+HUQ/E8hNL39jTgEZR5LifbbtZ5PTxHarBEh6T5tns1O3yuhnq3/nXcS30cjTJqBVNJh9r+naQmE+t6uoroqIlNY5/sNKyn9YSkF1P2HvgGZS7Q9pKOtv3lVjHVX+uXUSarbUPZSvhNtB3hZEn3sP1Xyoi5fwEuaRjPQpLuBdxh+y/AyZLmzfbVYJLECHVs9ruA7Sm/sP4L+ED9kLSKqXPHLtuvGmcsA10xNR5n/0xJzxpR/jNJe9v+7LgD6mk9AbwDeIrtayTtSBmgcQplafUmJP0Q2JCyG+RJwAts/75VPNU7gfUpTWGnAKsAY98uYJjK9qVfBjYG1qwrMuw1F82FSRKjHUiZMPMy4JuUYZSfBvZsGNPwmPbVgZ0oo51a6uM4++nasFutS9THegJYaWhosGzfrrKXeku/oqwm8FTKl/Eqkk6yfVmrgIaXdLG9V6s4pvgMcKDtb9R+kr2BgynNz7MqfRIjSDrHdXvAoTbIpks7TCVpFeBE209pHctAH8bZjyLp4bb78KUM9KeeJJ0GbGf7Okm/oqyVtFIfRszVZpQnU5qcntbyc97TeVNnDVZZGPqOmpPlS3IlMdpiHwhJ96H90g6LsX2rpCvmog1yOdwHeGDrIGDhUMqXUEZ93AY8sW1Ei+lLPe1DGSp8HWUNoEtp2NQ0UP+/3Wz7h8APW8dDP7cOXuy7W9JWwJw0hydJjHaZpM1sn0VZJuB/gTlZF2WmOoZRfq42EWzRYlXYrnH2445jSkxvo/wnnkdZOuGFrSfS9bGeAGz/79D9XuzrLum9wGvLXe1DGWq6rxsuAe9+bh18lKRNbZ9D+QH7QUq9zbo0Ny2BpIcDv2699EXHMErZfp6kA22/pUFMGw4d9mKcvaTbKb+G32f7opaxDPSxnvpK0sWUtZHuB3zL9taSfmG7T1eCzbcOHqckiVgukh5P6WSEMp696T4X9Qt5V8rVxEqUq4mje3A10at66itJJwE72r5p0Dc43EcY47dS6wBiZiStLumDkubX24ckNd2eU9I7KGvar1lvh0r615Yx2f617Y/VDrxdKU2q320ZUx/rqcf+D/h5HTa8pqQjKcNOo5FcSUwISYdT2kMPrkX7AGvY/oeGMV0IbGr7lnq8KnCO7Ye3iqnGcTfg4ZQ+gAttL2gcTy/rqY8k/dvQ4c3A+ba/3yqeSMf1JNnC9mOHjt9aO0Rbuooylv2WerxKLWtG0qaUGcTXAI8BzpP0psbNO72rp77qSwf6sOkmskKbSZG6857bi/Es7rudJDE5Rv0abt1p9mvgdEmD5pydgNMG/6kazSj+NLCb7VPrJKOdKBMit20Qy0Af66mXplvdVNJ7bE/7hT1HhidDvhX4xJTjFv9+w4uQvhQ4aspxksQK6D2S1hjsI1HHkrf+cjmj3gaab/EK3Mf2qfW+bP+pdd8N/aynvvreNI81WS3X9sKkIOkfphy/slFMbxqK4WlTjmd14mGSxISw/R1Jm9ZEcbnt6ylLYreM6RNLftbYzZO0cu2HWKkOVfxjy4B6Wk+9ZPtb0zx2Ytdj4yDpecAmkja3fYakh1KaDlvGtAXwcEkb2v61ymrRs7oneJLEhJB0GLAZcE9JH6dcXv677Tc0jKmPTQMHAg+jbAzzO8oija9uEMdCPa2nXlJZpn9UXT1d0udarJ0kaXPKgp9PoGxo9UmVza1Wp6yZNHaS1gP+BdgNeCPwHUm3AA8FPjCr58ropskg6QLgkZRlFH5sewtJ/2t7q4YxvWhUue1vSXpG619+fZF6mrn6hXwn9Zf7I9xgv4u6rtUngcNt31rL1gKuazUpUmU748Mpi/xdXddy2xT4vWd5/+0kiQkh6XjglbavknQ28Hjg7CkjnlrENVhn55YlPnkFlnqauTpC7Qbbl7eOZaBvMdV+tpUZw2cqk+kmx/XA2bXZ6f6UNW1abw7/PuAC4ApJO0taQ9K7WsbUR6mnmauf7yOA4yW9rtbVfyamO9mPMX2mciUxISTtNnR4M/BL2+e1igcmZ52d1lJPM9fTZtU+xjS2z1Q6rieE7SNbxzDC74G7uWyheo9adveWAUnaCTgAuIGybelvgG08tHFMA72rpx77DbBObVZdWdJKtK+rPsY0ts9UksSEUA83PmHROjvfoD/r7HwS2AV4APBx29tLeifTj7+fa32sp74aNKv+gJ40q9LPmMb2mUpz04So458HVqXsR7yO7Xe3iaif6+xoaHcuLVpF9HTbWyzptXMYU+/qqa962qzax5jG9plKkphgrb/8+kjSh4G1KR2NnwE+BrzE9nZNA4uJpkWLRkJZNPK2lvEMSLongO3p9nZfLmlumhB1ZuXAPMraLU3//aab+NQgnIHBHr8HAJdROhxf0S6c3tZTL/WxWbX+3zsa+ANlZeEHSHqp7dMaxvRQ4EjKNriu8yZeYfuS2T5XksTk+OjQ/QXAFZT9m1sa3tJ1VeBFQNMd12w/o+X5O/SunnpseD/phc2qjWIZ+A/K1ejpsHDC36eBJzeM6bPAh20fU2PaiXLl/OzZPlGam2JWtR7aqTEuobw8WtfTJGndrCrpLNubLalszDGdbftx44gpVxKxzCTdb+hw0AR2n0bhDEz3ZSJmcQnlmeppPfVSH5tVgb9Kuueg3b/2A9zcOKZbJa0ytEzIKozeTmC55UoiltlQ+7FZ1AT2bts/axpYz6SeZq723wwM6uqjtv+vUUjUeQi3DNZpkjQPWM32XxrGtBFwle2/1ePVgPVsXzbr50qSmAyS7j74QEQ3SRsCBwFPonwx/xzY1/YVTQOLiSVJwGsoKwob+C/gC7abbvol6dnDMdk+fi7Ok7WbJsdvJH1Z0t/X4Xgx2mGUiU7rUSY+fQ04tGlEMeneDzyH0ln8WMoQ6w+1DEjSvsB7gQuBnYFdJP3T9K9axnPlSmIy1HbQ5wBfoMwAPQ74KvAT5x9xoT52MsZkU9lLfnPbCySdafvxrQce1Jj+zvZfJJ1he/O5Wk8qVxITwvZNtr8GXEOZ1PMT4G3AZZIObBlbz1wj6dV1jZ2VJe1BqbOIZaW602E5KJ3EqzaMB4ChPhHVJrE52SUvSWLyqH44vkuZ4PM7ylpF4w9Eup+kN0nafbDwmdrvJ70HZfew39XbTrWsmZ7WU8zc1So70QHcG/gZcHDDeABulPSAen914FjmaDvjNDdNkDrK4lLKh3QrSpPTV2w32SBe0inAaZTJTn8E9ge+Y/tZLeLpq9TTZJN0L2CB7b9JehZwUeuBEJI2Bm6yfU29Wr7I9slzca7W449jhupqj08Bjqf0RezaauvEIavbfnNdOvlM2zdJWqNlQJpmP+kG4Qz0rp5i5mzfOHT/v1vGMmQT4Nx6/2TgsZLuYfuvs32iNDdNjqOBjWy/yvZxPUgQAPMlPb0OBbyjThprPfLqe5SmuO9Shireg7K3REt9rKeYbB8Frq0/Nn5EGQr7tbk4Ua4kJscjgUeV/qlFbL+nTTgAbA3sIekKSlPKqZTO9GZsf2tK0VcltZ601rt6iol3h+1bJO0MHG17f0lnzsWJkiQmx/BSwKsCO1L6J1racej+zbavbhZJB0mPBNZtHEbv6ym61dFMOwDXt+r/G+FWSc8F9gLeWcvmzcWJ0nE9oWr79k9sP7V1LH0i6QYWLYFh4Grg7SOuMMYZ04NGlbfu/IyZkXQccBuwJnAicCBwmO0XNoxpc0pyOMP2+2vn+g62vz7r50qSmDx1TPRjgWMar7M//IV8p4dt32vMIfVSnfg0qKdVgY2Bi20/qmlgMSOSzrf9aEmrAr+wvdnwDoh3dWlumhBTvpDvBtwBvLJlTLbv3fL8Xca1ps1M2d50+FjSY4F9G4UTS+9CSY+wfYGkwWJ6q7UOalySJCbE1C9kSdsBz2SOJtDMlKQXAtvUw5/Z/mbjePYFXk5Zr2l/4N6SHmf7Yy3jGmb7XElPah1HzNgawJmSTgUeRJnz8qm2IY1PmpsmmKRzpv5KHfP5PwxsShmeC/Ay4Bzb/9wwprGtabMUMQ2PZFq4n4TtHRqFFEtB0nC/382UiWvXtYpn3HIlMSEkHTB0uBKlT+LKRuEMPAd43NCSyYdLOhdoliRgfGvaLIXhJTgWAMcATa+4YuZs/7R1DC0lSUyOG4fuLwAOB77fJpSF7gDuR11AT9I6taylGyU9wPbvmOM1bWbK9nsBJN2nHl/fMp5YOlM2jYJFM/pNaY1pNnhkHNLcNEHqPhIPp3w4LxxembJRPLtQZn6eVGPaFvjnulptq5jGtqbNUsS0OaWPZE1KPV0P/IPt01vGFTMj6b7TPW772nHF0kKSxISQtCllM51rgMcA51F2XDujcVzrUBYbBDjN9lUt4+kjSWcBb7B9Sj1+MnBw9riYHJIez6IBGie3/n83Tlm7aXJ8GtjN9pOBSyhLYH+iZUCSnkZZLuTGentELYvF3TFIEAB1b+v8OpsQkt5C2fHwvvV2mKS3to1qfHIlMSGGd1cb2h2r6YQeSccOHa5KuaI4y/bTG4XUS5IGW11+uf75qvrnwZCZ131XB2M8wfbN9Xg1ylXzY9tGNh7puJ4c8yStXPshVpK0K2VvgmZs7zR8LGk94KBG4fTZc6b8ObADpRN0hfiymWBm8XWR5rECXQkmSUyOA4GHAb+k7Li2PfDqlgGN8AdKf0kMaTmXJWbF54FTJQ1Gyb2olq0Q0twUy0zSQSwaDjgP2Ay4xParul8VMXkkPY5FHdcn2T67ZTzjlCQxISSdyOgd15q1/0vabehwAXD5cAdtxF3Bir6Kb5LEhKhj7QdWB14C3Gb7HxuFBPRv7kbEbFvRV/FNkphgPViTqJdzNyLm0mAVX9t7tY5lHDJPYrJ9VdKc7EY1Q72bu9FHkpI070JsnwusMKv4ZnTThJiywN9Ctm+XtLftz447JspKpqfW+7L9J0mrT/uKFZDtzZf8rOirjlV8Wy+uOTZJEpPjxmke+8s0j82l3s3diJgDK/QqvumTmDCS7glg+6YexLIn8HPbv5T0A8r8jXdk/abFSfq87de2jiOWT91H+o6hpehXCEkSE0LSQ4EjgQdSRln8DniF7UuaBhZLJGnzdOZPLkkbAV+ijGpaEzgF2Mv2pQ3DGpt0XE+OzwIftv1A2xsC/w58pnFMMQNJEBPvEOBA2+sDFwB7U9fdWhEkSUyOtWwfMziwfSywdsN4YoYk7d06hlgu69n+Rr2vevW+VsuAxilJYnLcKmnhNpz1fiauTYa06U62xQb4SNoK+GujWMYufRIToraLXmX7b/V4NcovnMtaxhVxVyfpncCxts+RdB5wFfB62//XOLSxSJKYEJLuB7yCsvXllyl7Sd99RRtpERHjleamyfFd4CGUPQg+CdyDMl47ImLOZDLd5Fjd9pslrQScafsmSWu0Dioi7tpyJTE55kt6uu07gDtq89PdWgcVEXdt6ZOYEJLOBx4JXAGsQ5lM97Y6FDYiYk4kSUwISRsOHd5s++pmwUTECiNJYkKs6LtjRUQbSRITYkXfHSsi2sjopglhe9Ph48HuWI3CiYgVRK4kJpik82w/pnUcEXHXlSuJCbGi744VEW0kSUyOFXp3rIhoI81NERHRKTOuIyKiU5JERER0SpKIiIhOSRIREdEpSSIiIjr9f0CCGlRpnSxeAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "health_coverage_coding = [\n",
        "    'With public health coverage',\n",
        "    'Without public health coverage']\n",
        "\n",
        "# Bar graph by target of interest\n",
        "(acs_public_coverage_data\n",
        " .groupby([prediction_task.target])\n",
        " .size()\n",
        " .set_axis(health_coverage_coding)\n",
        " .plot(kind='bar', rot=0))"
      ],
      "metadata": {
        "id": "4lZ2bW2nTrJ7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "668b4e8a-f47a-48dd-dec0-cb2ca48a3a8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f377e587610>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both bar graphs show that neither race or target label are evently distributed, and there seems to be a significant differences within them. You might want to take a moment to think about how this imbalance in distribution might affect the model's performance and fairness."
      ],
      "metadata": {
        "id": "Bl_S_B_SO-ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "sI6MNm1RPFGx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, you will define your training function with Logistic Regression. You can check out sklearn documentation for [Logistic Regression ](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)here. \n",
        "\n",
        "We will be using the [`make_pipeline`](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html) and [`StandardScaler()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)when initializing the Logistic Regression model. You can read their documentations to learn more about these two functions. "
      ],
      "metadata": {
        "id": "AzkqMprrQiZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(X_train, y_train):\n",
        "  \"\"\"\n",
        "  Defines and trains a logistic regression model on the training data.\n",
        "\n",
        "  Args:\n",
        "    X_train (np.ndarray): Training inputs.\n",
        "    y_train (np.ndarray): Training labels.                 \n",
        "\n",
        "  Returns:\n",
        "    sklearn.pipeline.Pipeline: trained model\n",
        "  \"\"\"\n",
        "  # TODO: train model\n",
        "\n",
        "  LR_pipeline = make_pipeline(StandardScaler(), LogisticRegression()).fit(X_train, y_train)\n",
        "  \n",
        "  return LR_pipeline"
      ],
      "metadata": {
        "id": "6K456CTaPISI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluation"
      ],
      "metadata": {
        "id": "LnsKd2vDPLEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, you can implement the three fairness measurements: independence, separation, sufficiency. With these three measurements, we can evalution how fair our model is in making prediction.\n",
        "\n",
        "Here are how the measurements are calculated:"
      ],
      "metadata": {
        "id": "4VvhDEDAQrHB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition 1: Independence**\n",
        "\n",
        "*Random variables $(A, R)$ satisty independence if $A \\perp R$* \n",
        "\n",
        "Let $\\text{independence} = \\frac{P\\{ \\hat{Y} = 1\\ | A = a\\}}{P\\{ \\hat{Y} = 1\\ | A = b\\}}$\n",
        "\n",
        "Then $A \\perp R$ is equivalent to saying that $\\text{independence} = 1$\n",
        "\n",
        "Here, $\\hat{Y}$ is our prediction from the model and $A$ is the feature we want to evaluate the independence against the prediction on. \n"
      ],
      "metadata": {
        "id": "59UZKKHfHzLw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import index\n",
        "\n",
        "def independence(y_hat, group):\n",
        "  \"\"\"\n",
        "  Computes an independence metric between two specific groups.\n",
        "\n",
        "  Args:\n",
        "    y_hat (np.ndarray): Classifier predictions.\n",
        "    group (np.ndarray): Array of indices corresponding to group membership.\n",
        "      For this assignment, we will focus on comparing groups 1 and 2.\n",
        "      These correspond to the 'White alone' and 'Black or African American'\n",
        "      groups. Note that one can also compare different combinations of groups.                 \n",
        "\n",
        "  Returns:\n",
        "    float: independence measure\n",
        "  \"\"\"\n",
        "  # TODO: compute measure\n",
        "\n",
        "  idx1 = np.where(group == 1)[0]\n",
        "  idx2 = np.where(group == 2)[0]\n",
        "\n",
        "  P1 = sum(y_hat[(idx1),])/len(y_hat[(idx1),])\n",
        "  P2 = sum(y_hat[(idx2),])/len(y_hat[(idx2),])\n",
        "\n",
        "  indep = P2/P1\n",
        "\n",
        "  return indep"
      ],
      "metadata": {
        "id": "pY6Jck63H4lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition 2: Separation**\n",
        "\n",
        "*Random variables $(R, A, Y)$ satisfy separation if $R\\perp A| Y$*\n",
        "\n",
        "In the case of a binary classifier (what we are doing in this assignment, separation is equivalent to requiring for all groups $a,b$ the two constraints\n",
        "\n",
        "$\\text{Separation}_{\\text{true positive}} = \\frac{P\\{ \\hat {Y} | Y = 1, A = a\\}} {P \\{\\hat{Y} | Y = 1, A = b\\}}$\n",
        "<br>\n",
        "<br>\n",
        "$\\text{Separation}_{\\text{false positive}} = \\frac{P\\{ \\hat {Y} | Y = 0, A = a\\}}{P \\{\\hat{Y} | Y = 0, A = b\\}}$"
      ],
      "metadata": {
        "id": "u4EhA0wYH_lM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def separation(y_hat, y_true, group):\n",
        "  \"\"\"\n",
        "  Computes a separation metric between two specific groups.\n",
        "\n",
        "  Args:\n",
        "    y_hat  (np.ndarray): Classifier predictions.\n",
        "    y_true (np.ndarray): Data labels.\n",
        "    group  (np.ndarray): Array of indices corresponding to group membership.\n",
        "      For this assignment, we will focus on comparing groups 1 and 2.\n",
        "      These correspond to the 'White alone' and 'Black or African American'\n",
        "      groups. Note that one can also compare different combinations of groups. \n",
        "\n",
        "  Returns:\n",
        "    float: separation true positive\n",
        "    float: separation false positive\n",
        "  \"\"\"\n",
        "  # TODO: compute measure\n",
        "\n",
        "  idx1_1 = np.intersect1d(np.where(y_true == 1)[0], np.where(group == 1)[0])\n",
        "  idx1_2 = np.intersect1d(np.where(y_true == 1)[0], np.where(group == 2)[0])\n",
        "  idx0_1 = np.intersect1d(np.where(y_true == 0)[0], np.where(group == 1)[0])\n",
        "  idx0_2 = np.intersect1d(np.where(y_true == 0)[0], np.where(group == 2)[0])\n",
        "\n",
        "  P1_1 = sum(y_hat[(idx1_1),])/len(y_hat[(idx1_1),])\n",
        "  P1_2 = sum(y_hat[(idx1_2),])/len(y_hat[(idx1_2),])\n",
        "\n",
        "  P0_1 = sum(y_hat[(idx0_1),])/len(y_hat[(idx0_1),])\n",
        "  P0_2 = sum(y_hat[(idx0_2),])/len(y_hat[(idx0_2),])\n",
        "\n",
        "  TP = P1_2/P1_1\n",
        "  FP = P0_2/P0_1\n",
        "\n",
        "  return TP, FP"
      ],
      "metadata": {
        "id": "FL0CISNEH_YL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Definition 3: Sufficiency**\n",
        "\n",
        "*We say the random variables $(R, A, Y)$ satisfy sufficiency if $Y\\perp A | R$*\n",
        "\n",
        "In a binary case where $Y \\in \\{0, 1\\}$, a random variable $R$ is sufficient for $A$ if and only if for all groups, $a,b$ and all values $r$ in the support of $R$, we have\n",
        "\n",
        "$\\text{sufficiency} = \\frac{P\\{Y = 1 | R = r, A = a\\}}{P\\{Y = 1 | R = r, A = b\\}}$\n",
        "\n",
        "When we replace $R$ by a binary predictor $\\hat{Y}$, we recognize this condition as requiring a positive/negative predictive values across all groups."
      ],
      "metadata": {
        "id": "c5F71Ah7ILCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sufficiency(y_hat, y_true, group):\n",
        "  \"\"\"\n",
        "  Computes a sufficiency metric between two specific groups.\n",
        "\n",
        "  Args:\n",
        "    y_hat  (np.ndarray): Classifier predictions.\n",
        "    y_true (np.ndarray): Data labels.\n",
        "    group  (np.ndarray): Array of indices corresponding to group membership.\n",
        "      For this assignment, we will focus on comparing groups 1 and 2.\n",
        "      These correspond to the 'White alone' and 'Black or African American'\n",
        "      groups. Note that one can also compare different combinations of groups.\n",
        "\n",
        "  Returns:\n",
        "    float: sufficiency metric\n",
        "  \"\"\"\n",
        "  # TODO: compute metric\n",
        "\n",
        "  idx1_1 = np.intersect1d(np.where(y_hat == 1)[0], np.where(group == 1)[0])\n",
        "  idx1_2 = np.intersect1d(np.where(y_hat == 1)[0], np.where(group == 2)[0])\n",
        "\n",
        "  P1_1 = sum(y_true[(idx1_1),])/len(y_true[(idx1_1),])\n",
        "  P1_2 = sum(y_true[(idx1_2),])/len(y_true[(idx1_2),])\n",
        "\n",
        "  suff = P1_2/P1_1\n",
        "\n",
        "  return suff"
      ],
      "metadata": {
        "id": "nQNUFg61IOpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here let's define an evaluation function based on our three implementations of fairness measurement!"
      ],
      "metadata": {
        "id": "tchzP_qhH68W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval(yhat, y_test, group_test, model_title):\n",
        "  print(\"Results from the \" + model_title + \" model: \")\n",
        "  print(\"the indepence of prediction and group is \", independence(yhat, group_test))\n",
        "  true_s, false_s = separation(yhat, y_test, group_test)\n",
        "  print(\"the true positive separation is \", true_s)\n",
        "  print(\"the false positive separation is \", false_s)\n",
        "  print(\"the sufficiency of the prediction and the group is\", sufficiency(yhat, y_test, group_test))"
      ],
      "metadata": {
        "id": "XyZD-rPOIcQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please feel free to use the following dummy data and predictions to unit test your own implementation. We encourage that you grab a pen and verify with simple calculation that this makes sense!\n",
        "\n",
        "The expected results:\n",
        "\n",
        "```\n",
        "Results from unit-testing model: \n",
        "the indepence of prediction and group is  0.6666666666666667\n",
        "the true positive separation is  0.75\n",
        "the false positive separation is  0.6666666666666666\n",
        "the sufficiency of the prediction and the group is 0.75\n",
        "```"
      ],
      "metadata": {
        "id": "1ZJp6onEcwQt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_example = np.asarray([True, True, False, False, True, False, False, False, True, True])\n",
        "y_test_example = np.asarray([True, True, True,  False, False, False, False, True, False, True])\n",
        "group_test_example = np.asarray([1, 1, 1, 1, 1, 2, 2, 2, 2, 2])\n",
        "\n",
        "eval(y_hat_example, y_test_example, group_test_example, \"unit-test\")"
      ],
      "metadata": {
        "id": "odfPPyGrcxve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "538e6c38-7bc9-4aa5-83af-e7bae50c3a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results from the unit-test model: \n",
            "the indepence of prediction and group is  0.6666666666666667\n",
            "the true positive separation is  0.75\n",
            "the false positive separation is  0.6666666666666666\n",
            "the sufficiency of the prediction and the group is 0.75\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Full Workflow"
      ],
      "metadata": {
        "id": "OhRLRCt2NFRE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, let's connect the whole pipeline with training and see how fair our model is! \n",
        "\n",
        "You will \n",
        "1. Do a train_test_split on the dataset on a 80-20 ratio with a `random_state = 0`\n",
        "2. Train your Linear Regression Model\n",
        "3. Use the trained model to make prediction on the test dataset\n",
        "4. Eval the model with fairness measurements. "
      ],
      "metadata": {
        "id": "Wg1shu3RI7lj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
        "    features, label, group, test_size=0.2, random_state=0)\n",
        "model = train(X_train, y_train)\n",
        "yhat = model.predict(X_test)\n",
        "\n",
        "eval(yhat, y_test, group_test, \"baseline\")"
      ],
      "metadata": {
        "id": "Y-kM9pF2I_y1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b350878b-f120-44d4-ec76-2746db922628"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results from the baseline model: \n",
            "the indepence of prediction and group is  1.6135056165484982\n",
            "the true positive separation is  1.3052337292915481\n",
            "the false positive separation is  1.2975609756097561\n",
            "the sufficiency of the prediction and the group is 1.196133899104196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2b: Resampling"
      ],
      "metadata": {
        "id": "FOV8_kFWP2uc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this section, we want you to retrain the model using inputs that have a different ratio of elements in demographic groups and then see how the fairness measures change if at all. For instace, you could modify the frequency at which different groups appear in the training set.\n",
        "\n",
        "Several approaches for achieving this kind of result are detailed in [Kamiran and Kalders 2012, Data preprocessing techniques for classification without discrimination](https://link.springer.com/article/10.1007/s10115-011-0463-8). We recommend implementing the Uniform Sampling method described in Algorithm 4 of the paper, but feel free to use any other viable method. In particular, Section 5.3 details the partitioning of the dataset into various groups of interest. We want to rebalance these groups but keep the total number of data points we train on to remain the same, so some data points will be skipped and others will be duplicated. As such, we must calculate the sample weights according to the formulas described in the paper for these different groups."
      ],
      "metadata": {
        "id": "w-WULQvsUe3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Weighting approach ###\n",
        "def compute_sample_weight(y, group):\n",
        "  \"\"\"\n",
        "  Computes sample weights according to the algorithm described in the paper.\n",
        "\n",
        "  Args:\n",
        "    y     (np.ndarray): Training labels.\n",
        "    group (np.ndarray): Array of indices corresponding to group membership.                 \n",
        "\n",
        "  Returns:\n",
        "    list: sample weight\n",
        "    dict: weight dict\n",
        "  \"\"\"\n",
        "  assert(len(y) == len(group))\n",
        "\n",
        "  # TODO: calculate sample weight\n",
        "\n",
        "  name_keys = [\"N1\", \"N2\", \"P1\", \"P2\"]\n",
        "  weight_values = []\n",
        "\n",
        "  for i in np.unique(y):\n",
        "    for j in np.unique(group):\n",
        "      numer = len(np.where(y == i)[0])*len(np.where(group == j)[0])\n",
        "      denom = len(y)*len(np.intersect1d(np.where(y == i)[0], np.where(group == j)[0]))\n",
        "      weight = numer/denom\n",
        "      weight_values.append(weight)\n",
        "\n",
        "  weight_dict = dict(map(lambda k,v : (k,v), name_keys, weight_values))\n",
        "\n",
        "  sample_weight = []\n",
        "\n",
        "  for p in range(len(y)):\n",
        "    if y[p] == 0:\n",
        "      if group[p] == 1:\n",
        "        sample_weight.append(weight_dict[\"N1\"])\n",
        "      else:\n",
        "        sample_weight.append(weight_dict[\"N2\"])\n",
        "    elif y[p] == 1:\n",
        "      if group[p] == 1:\n",
        "        sample_weight.append(weight_dict[\"P1\"])\n",
        "      else:\n",
        "        sample_weight.append(weight_dict[\"P2\"])\n",
        "\n",
        "  return sample_weight, weight_dict\n",
        "\n",
        "# NOTE: We will later use sample_weight in sensitive-cost training\n",
        "#       and weight_dict in uniform sampling\n",
        "\n",
        "sample_weight, weight_dict = compute_sample_weight(y_train, group_train)\n",
        "#print(weight_dict)"
      ],
      "metadata": {
        "id": "rNGB_izJskc4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the Uniform Sampling method, the chance of sampling any given point within a group is uniform. As described in the paper, \"all the data objects of the same group have the same\n",
        "chance of being duplicated or skipped\"."
      ],
      "metadata": {
        "id": "KW4zJpH1VjdK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Uniform sampling ###\n",
        "def uniform_sampling(X, y, group, weight_dict):\n",
        "  \"\"\"\n",
        "  Perform uniform sampling given a `weight_dict`\n",
        "\n",
        "  Args:\n",
        "    X     (np.ndarray): Training data.    \n",
        "    y     (np.ndarray): Training labels.\n",
        "    group (np.ndarray): Array of indices corresponding to group membership.\n",
        "    weight_dict (dict): Dict containing weights for different groups.             \n",
        "\n",
        "  Returns:\n",
        "    np.ndarray: Sampled training data\n",
        "    np.ndarray: Corresponding sampled training labels\n",
        "    np.ndarray: Corresponding sampled array of group membership\n",
        "  \"\"\"\n",
        "  # TODO: perform uniform sampling\n",
        "\n",
        "  idx_N1 = np.intersect1d(np.where(y == 0)[0], np.where(group == 1)[0])\n",
        "  idx_N2 = np.intersect1d(np.where(y == 0)[0], np.where(group == 2)[0])\n",
        "  idx_P1 = np.intersect1d(np.where(y == 1)[0], np.where(group == 1)[0])\n",
        "  idx_P2 = np.intersect1d(np.where(y == 1)[0], np.where(group == 2)[0])\n",
        "\n",
        "  samp_size_N1 = round(weight_dict[\"N1\"]*len(idx_N1))\n",
        "  samp_size_N2 = round(weight_dict[\"N2\"]*len(idx_N2))\n",
        "  samp_size_P1 = round(weight_dict[\"P1\"]*len(idx_P1))\n",
        "  samp_size_P2 = round(weight_dict[\"P2\"]*len(idx_P2))\n",
        "\n",
        "  samp_idx_N1 = [np.random.choice(idx_N1) for i in range(samp_size_N1)]\n",
        "  samp_idx_N2 = [np.random.choice(idx_N2) for i in range(samp_size_N2)]\n",
        "  samp_idx_P1 = [np.random.choice(idx_P1) for i in range(samp_size_P1)]\n",
        "  samp_idx_P2 = [np.random.choice(idx_P2) for i in range(samp_size_P2)]\n",
        "\n",
        "  samp_indices = samp_idx_N1 + samp_idx_N2 + samp_idx_P1 + samp_idx_P2\n",
        "\n",
        "  X_sampled = X[samp_indices]\n",
        "  y_sampled = y[samp_indices]\n",
        "  group_sampled = group[samp_indices]\n",
        "\n",
        "  return X_sampled, y_sampled, group_sampled\n",
        "\n",
        "# Sample from training data\n",
        "X_sampled, y_sampled, group_sampled = uniform_sampling(X_train, y_train, group_train, weight_dict)\n",
        "\n",
        "model = train(X_sampled, y_sampled)\n",
        "yhat = model.predict(X_test)\n",
        "eval(yhat, y_test, group_test, \"uniform_sampling\")"
      ],
      "metadata": {
        "id": "senZdDXsNLsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51c2b17b-83fd-4710-cc7a-6833be0b4fb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results from the uniform_sampling model: \n",
            "the indepence of prediction and group is  1.5410832732257516\n",
            "the true positive separation is  1.294126690594293\n",
            "the false positive separation is  1.171003717472119\n",
            "the sufficiency of the prediction and the group is 1.2416885597487477\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2c: Cost-Sensitive Learning"
      ],
      "metadata": {
        "id": "cgFck6RYQEK4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model using a different measure of cost (not accuracy, but cost-sensitive accuracy) and see what happens to the output.\n",
        "\n",
        "It may be helpful to look at the documentation for the `LogisticRegression` classifier: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html.\n"
      ],
      "metadata": {
        "id": "xuhFuzzoV7cQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_weighted(X_train, y_train):\n",
        "  \"\"\"\n",
        "  Defines and trains a logistic regression model on the training data.\n",
        "  Applies weighting on training the model.\n",
        "\n",
        "  Args:\n",
        "    X_train (np.ndarray): Training inputs.\n",
        "    y_train (np.ndarray): Training labels.                 \n",
        "\n",
        "  Returns:\n",
        "    sklearn.pipeline.Pipeline: trained model\n",
        "  \"\"\"\n",
        "  # TODO: train model\n",
        "  \n",
        "  sample_weights = np.array(compute_sample_weight(y_train, group_train)[0])\n",
        "\n",
        "  LR_pipeline = make_pipeline(StandardScaler(), LogisticRegression())\n",
        "  model_train = LR_pipeline.fit(X_train, y_train, \n",
        "                                logisticregression__sample_weight = sample_weights)\n",
        "\n",
        "  return model_train"
      ],
      "metadata": {
        "id": "gVanX1bdDNE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_model = train_weighted(X_train, y_train)\n",
        "yhat = weighted_model.predict(X_test)\n",
        "\n",
        "print(\"Results from a model trained with weighting approach: \")\n",
        "print(independence(yhat, group_test))\n",
        "print(separation(yhat, y_test, group_test))\n",
        "print(sufficiency(yhat, y_test, group_test))\n",
        "\n",
        "#eval(yhat, y_test, group_test, \"weighted\")"
      ],
      "metadata": {
        "id": "oaw54gF0T97W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc8e0087-485e-4254-da1c-cf45090cd20d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results from a model trained with weighting approach: \n",
            "1.5036432659126076\n",
            "(1.2457235915065032, 1.1630769230769231)\n",
            "1.2250078385288548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Part 3: Analyzing a particular mathematical notion of fairness\n",
        "\n",
        "In our exploration of fairness measures we've been considering how to evaluate the fairness of a binary classifier that produces a 0-1 output. \n",
        "\n",
        "In various exploratory data mining tasks the goal is to *cluster* a collection of objects into groups and determine whether the groups have some meaningful structure. \n",
        "\n",
        "Formally, we are given a set of $n$ points, where each point is represented by a $d$-dimensional feature vector $x \\in R^d$. We define the *distance* between two points as the Euclidean distance between them: \n",
        "\n",
        "$ d(x,y) = \\sqrt{\\sum_{i=1}^d (x_i - y_i)^2}$\n",
        "\n",
        "And then we define the $k$-means problem as: \n",
        "\n",
        "Partition the points into $k$ clusters $C_1, \\dots, C_k$ such that the sum of squared distance from each point to its cluster center is minimized, where the center of a cluster is defined as the centroid of the cluster:  \n",
        "$\\mu(C) = \\sum_{x \\in C} x/|C|$\n",
        "where $|C|$ is the number of points in the cluster. More precisely, the goal is to find $C_1, \\dots, C_k$ such that \n",
        "\n",
        "$\\sum_{j=1}^k \\sum_{x \\in C_j} d^2(x, \\mu(C_j))$ is minimized. \n",
        "\n",
        "Now consider a \"fair\" equivalent of this problem. Now each point $x$ also has a color $g(x)$. For any clustering we can write down the fraction of points within a cluster having a particular color. \n",
        "\n",
        "Then the goal is to make sure these fractional values for each cluster match the overall proportions of colors. For example, if we have 15 points of which 5 are red and 10 are blue, and we want to cluster them into 5 clusters, then in each cluster there should be 1 red and 2 blue points. \n",
        "\n",
        "Consider two scenarios in which one might wish to cluster points. \n",
        "\n",
        "1. Each point encodes different kinds of qualifications. The clusters represent people with similar qualifications. The \"color\" of a point is a gender encoding. The goal of the clustering is to group people into categories to target them with different kinds of job ads. \n",
        "\n",
        "2. Each point represents the location of a voter in a state. The clusters represent voting districts for a state assembly. The \"color\" of a point is the person's registered political affiliation (assume that there are two parties). \n",
        "\n",
        "Assess the degree to which the fairness measure eliminates any form of bias that one might be concerned with in the scenarios described. "
      ],
      "metadata": {
        "id": "KHdnyNtbM1PU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Type in your reponse here ###"
      ],
      "metadata": {
        "id": "F49fzOyLflXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Response\n",
        "\n",
        "**Scenario (A):**\n",
        "\n",
        "- Individuals are clustered based on qualification features for the purpose of targeting them with corresponding job ads.\n",
        "\n",
        "- <u>Fairness Measure</u>: Clusters maintain the same gender proportions as the data.\n",
        "\n",
        "**Metric Evaluation:**\n",
        "\n",
        "- If we have balanced data, this clustering scheme would ensure that outcomes are relatively evenly distributed between “color” groups for similar qualifications.\n",
        "\n",
        "- If we have imbalanced data, then:\n",
        "\n",
        "  - It’s possible for clusters to maintain any systemic bias that may be present in the data. For example, if there are considerable quality and pay differences between jobs being advertised, then the majority group will inevitably receive more ads for better paying jobs. However, the fact that the inverse would also hold true (i.e., the majority group would also receive more ads for jobs with inferior benefits) could be seen as a way of \"evening out\" this unfairness given that the degree to which each group benefits or is harmed by the algorithm would be relative to its size. That is, unless a “benefit” holds more weight than a “harm”, say.\n",
        "\n",
        "  - It could be the case that correlation between clustering features and \"color\" attribute sees naturally occurring (qualification-based) clusters for which gender proportions vastly differ from that of the whole data. When this holds, the proposed fairness metric would yield sub-optimal clusters and prompt the algorithm to give inaccurate job ads. This is particularly concerning for imbalanced data since the clustering cost would not be evenly distributed among groups, which in this context, means the minority class receives disproportionately more inaccurate or irrelevant job ads.\n",
        "\n",
        "**Scenario (B):**\n",
        "\n",
        "- Voters' locations are clustered into voting districts for a given state.\n",
        "\n",
        "- <u>Fairness Measure</u>: Clusters maintain the same political affiliation proportions as the data.\n",
        "\n",
        "**Metric Evaluation:**\n",
        "\n",
        "- The proposed clustering scheme in this scenario would not only be ineffective in the face of balanced data, but is considered to be a specific form of *gerrymandering* that would otherwise result in an unfair political election. Although clustering in this way ensures that the distribution of political parties for a given district is consistent with that of the whole state, it does not ultimately yield a fair partitioning of districts that themselves reflect this desired distribution. That is, since every district would be won over by the majority class, the minority class would remain completely unrepresented at the state level and suffer from a compromised chance of winning the election. \n"
      ],
      "metadata": {
        "id": "CQ5PPFQafmSE"
      }
    }
    }
  ]
}
